---
title: L02-微积分
date: 2022-05-13 23:28:46
tags: 人工智能、机器学习、深度学习
categories: 
- 人工智能
- 人工智能数学基础
cover: https://tva1.sinaimg.cn/large/e6c9d24ely1h2771gvamvj20dw098q3x.jpg
---

# 函数

## 本质

- 从一个集合到另一个集合的**映射规则**

<img src="https://tva1.sinaimg.cn/large/e6c9d24ely1h26smvi197j209a02qweb.jpg" style="zoom:33%;" />

- 可以源于“天然”

<img src="https://tva1.sinaimg.cn/large/e6c9d24ely1h26sn47h6cj20fy02qwef.jpg" style="zoom:33%;" />

- 也可以“人工”创造，如狄利克雷函数

<img src="https://tva1.sinaimg.cn/large/e6c9d24ely1h26sn8r7bgj20o605yt8z.jpg" style="zoom:33%;" />

Q：狄利克雷函数的图像应该是什么样？

<img src="https://tva1.sinaimg.cn/large/e6c9d24ely1h26sp7rs6nj211k0lyab5.jpg" style="zoom:33%;" />

​       客观存在，然而**无法画出**

## 表示形式

- 解析式：y = sinx
- 文字描述：自变量为无理数时因变量取值0，有理数时取值1
- 列表法

## 三要素

- 定义域(整数域，实数域，复数域...)
- 值域(整数域，实数域，复数域...)
- 映射法则(将定义域映射到值域)

<img src="https://tva1.sinaimg.cn/large/e6c9d24ely1h26ssrxfmnj20ry0jugmw.jpg" style="zoom:33%;" />

​       注意！**不是所有的映射法则都可以构成函数**。**同一个自变量，在值域中有且只能有一个因变量与之对应**

# 极限

## 定义

- 什么叫无限逼近某一个量？
- 这个量可以“到达”吗？
- 正式定义：

<img src="https://tva1.sinaimg.cn/large/e6c9d24ely1h26sw0kzshj21ve07kjtw.jpg" style="zoom:33%;" />

<img src="https://tva1.sinaimg.cn/large/e6c9d24ely1h26swf7b6hj20ec042mx3.jpg" style="zoom:33%;" />

# 连续

## 直观上

- 不断裂
- 不跳跃
- 处处相连

<img src="https://tva1.sinaimg.cn/large/e6c9d24ely1h26t3ese8tj20oa0gwjrr.jpg" style="zoom:33%;" />

<img src="https://tva1.sinaimg.cn/large/e6c9d24ely1h26t3ljh4pj20j80jyt97.jpg" style="zoom:33%;" />

<img src="https://tva1.sinaimg.cn/large/e6c9d24ely1h26t3s8n1aj20kq0kudgx.jpg" style="zoom:33%;" />

## 定义

​       设函数f(x)在点x0的某个领域内（例如（x0 - 0.0001，x0 + 0.0001））有定义，如果有：

<img src="https://tva1.sinaimg.cn/large/e6c9d24ely1h26tay2b56j20go04igll.jpg" style="zoom:33%;" />

则称函数f(x)在点x0处连续，x0称为函数f(x)的连续点。

​       **函数在连续点的极限就是连续点的函数值！**

# 导数

## 定义

<img src="https://tva1.sinaimg.cn/large/e6c9d24ely1h26tj0ffpmj210a06amxl.jpg" style="zoom:33%;" />

## 几何意义

​       函数图像上一点的导数的值为在该点切线的斜率，代表了函数在该点的变化率

## 导数计算

- 常用函数的导数

<img src="https://tva1.sinaimg.cn/large/e6c9d24ely1h26tlqaa2oj214w0nwgno.jpg" style="zoom:33%;" />

- 导数运算法则

<img src="https://tva1.sinaimg.cn/large/e6c9d24ely1h26tmbvmjtj21ek0dctaj.jpg" style="zoom:33%;" />

## 代码演示

### 迭代法求解二次函数最小值

```python
import numpy as np
import matplotlib.pyplot as plt
from IPython import display

#定义二次函数
def f(x):
    y = x**2
    return y

# 定义对应的导数
def d(x):
    dy = 2*x
    return dy

# 操作者输入指定的x初始值
x = float(input("请输入x的初始值："))

# 定义学习率
lr = 0.9

# 准备一段二次函数数据点
x_temp = np.linspace(-x, x, 1000)
y_temp = x_temp**2

while abs(x) > 0.01:
    display.clear_output(wait=True)   # 用于清空之前的输出
    plt.clf()                         # 清除之前的列表
    plt.plot(x_temp, y_temp)
    plt.scatter(x, f(x), s=30, c='red')
    plt.show()
    print("此时x的值为：", x)
    plt.pause(0.7)
    %matplotlib inline
    dy = d(x)
    x -= lr * dy
else:
    display.clear_output(wait=True)   
    plt.clf()
    plt.plot(x_temp, y_temp)
    plt.scatter(x, f(x), s=30, c='red')
    plt.show()
    print("最终x的值为：", x)
```

结果：

<img src="https://tva1.sinaimg.cn/large/e6c9d24ely1h26u65p58gj20mm0dsq3k.jpg" style="zoom:33%;" />

## 二阶导数

<img src="https://tva1.sinaimg.cn/large/e6c9d24ely1h26u75oc4cj20gc04cglk.jpg" style="zoom:33%;" />

“阶”：几阶就对函数求几次导

# 微分

- 定义：

​       当自变量x的变化趋于无穷小时（dx），因变量f(x)的变化情况（df(x)）

<img src="https://tva1.sinaimg.cn/large/e6c9d24ely1h26u9nl5c4j20fm03yjrc.jpg" style="zoom:33%;" />

- 导数和微分

  - 导数：函数在某一点的变化率
  - 微分：函数在某一点的变化量
  - 联系：函数的变化量与自变量变化量之比即为导数

  <img src="https://tva1.sinaimg.cn/large/e6c9d24ely1h26ub9ujrej20dc04omx4.jpg" style="zoom:33%;" />

# 链式法则

​       嵌套函数：

<img src="https://tva1.sinaimg.cn/large/e6c9d24ely1h273i7z5brj20iu02c3yh.jpg" style="zoom: 50%;" />

​       如何求y相对于z的导数？

<img src="https://tva1.sinaimg.cn/large/e6c9d24ely1h273j4e9gxj210g03o3yv.jpg" style="zoom: 50%;" />

​       看似简单，但是链式法则的真面目是·······

<img src="https://tva1.sinaimg.cn/large/e6c9d24ely1h273kv9p2wj20qm0k840a.jpg" style="zoom:33%;" />

​       **神经网络优化原理——反向传播的基石！～**

# 偏导数

<img src="https://tva1.sinaimg.cn/large/e6c9d24ely1h273nwwelhj20w806at9f.jpg" style="zoom: 50%;" />

本质：

- 仅仅因为是多元函数的导数，所以多了一个“偏”字
- 求解的过程和导数无异，**将其他变量视作常量**

<img src="https://tva1.sinaimg.cn/large/e6c9d24ely1h273po1q4ej20k002waa4.jpg" style="zoom: 50%;" />

# 方向导数

​       几何上，偏导数沿着自变量方向...

<img src="https://tva1.sinaimg.cn/large/e6c9d24ely1h274099yx1j20o80je41a.jpg" style="zoom:33%;" />

​       能不能沿任意方向求导数?——可以

- 一元函数中，自变量在函数曲线上只能沿着**两个方向**移动
- 多元函数中，自变量在函数曲面上可以沿着**无穷多个方向**移动
- 多元函数中，函数的变化不仅与移动距离有关，和移动方向亦有关

## 方向余弦

​       定义：向量与三个（或两个）坐标轴之间的角度的余弦：

<img src="https://tva1.sinaimg.cn/large/e6c9d24ely1h274jz32ohj20i803emx9.jpg" style="zoom: 50%;" />

<img src="https://tva1.sinaimg.cn/large/e6c9d24ely1h274l4c87jj20i402a74a.jpg" style="zoom:33%;" />

<img src="https://tva1.sinaimg.cn/large/e6c9d24ely1h274lfp20oj205q022wea.jpg" style="zoom:33%;" />

<img src="https://tva1.sinaimg.cn/large/e6c9d24ely1h274my8xoej20hi07smxn.jpg" style="zoom:33%;" />

## 方向导数求解

<img src="https://tva1.sinaimg.cn/large/e6c9d24ely1h274o2aq0fj20me0h8wg4.jpg" style="zoom: 50%;" />

<img src="https://tva1.sinaimg.cn/large/e6c9d24ely1h274pfefigj20cu04kdfu.jpg" style="zoom: 50%;" />

​       令l的方向余弦为：

<img src="https://tva1.sinaimg.cn/large/e6c9d24ely1h274r8s60cj208o020web.jpg" style="zoom:50%;" />

​       令t = ｜P' P｜，则点P'可表示为：

<img src="https://tva1.sinaimg.cn/large/e6c9d24ely1h274sduluxj20jg024wee.jpg" style="zoom:50%;" />

<img src="https://tva1.sinaimg.cn/large/e6c9d24ely1h274v82ycsj211404074k.jpg" style="zoom:50%;" />

<img src="https://tva1.sinaimg.cn/large/e6c9d24ely1h274vuv9mpj20ws06kgm0.jpg" style="zoom:50%;" />

- [fx fy]：梯度
- 后一部分：l方向的方向余弦，且其长度为1

​       显而易见，函数f(x)在l方向上的导数就是在该点的梯度和l方向的方向余弦的**内积**

​       Tips：当两部分**方向一致**的时候，他们的**内积最大**，**梯度的方向是函数变化最快的方向**。

# 梯度

## 定义

- 梯度的方向是函数变化最快的方向
- 各个方向的偏导数构成的向量

<img src="https://tva1.sinaimg.cn/large/e6c9d24ely1h2753ufb0qj209q02o3yf.jpg" style="zoom: 50%;" />

<img src="https://tva1.sinaimg.cn/large/e6c9d24ely1h2754msoqgj20hm0343ym.jpg" style="zoom: 50%;" />

- 人工智能中为什么要用梯度下降算法？——**几乎很少有情形是可以直接求出解析解的**
  - 解析解：可以直接计算出的精确解
  - 数值解：用数值方法逼近求的近似解

​       然而对于更复杂一些的函数······

<img src="https://tva1.sinaimg.cn/large/e6c9d24ely1h2758j8002j20no0j643d.jpg" style="zoom:33%;" />

- 局部极小值点
- 驻点
- 学习率（步长）的大小
- 初始化方法
- ·······

## 梯度下降

<img src="https://tva1.sinaimg.cn/large/e6c9d24ely1h275bmg5r9j20ck06e74f.jpg" style="zoom:50%;" />

​       进行迭代：

<img src="https://tva1.sinaimg.cn/large/e6c9d24ely1h275fj9k6tj2088054jra.jpg" style="zoom: 50%;" />

​       结果：

<img src="https://tva1.sinaimg.cn/large/e6c9d24ely1h275anof0aj20ro0lm767.jpg" style="zoom:33%;" />

# 积分

## 代码演示

### 对规则图形求面积

- 绘制一条曲线

```python
import numpy as np
import matplotlib.pyplot as plt
from IPython import display

x_temp = np.linspace(1, 10, 1000)
y_temp = 2*x_temp + 3

%matplotlib inline
plt.plot(x_temp, y_temp)
plt.xlim(0,11)
plt.show()
# display.clear_output(wait=True)
```

<img src="https://tva1.sinaimg.cn/large/e6c9d24ely1h275lrbug5j20l40b6weo.jpg" style="zoom:50%;" />

- 输入区间，计算面积

```python
def reg_area(p1, p2):
    # p1, p2: 点的坐标
    if p1[0] < 0 or p1[1] < 0 or p2[0] < 0 or p2[1] < 0:
        print("点坐标为负，非法！")   # 若点的坐标有负值，则不可计算
        return -1
    height = abs(p2[0] - p1[0])  # 求梯形的高
    l1 = p1[1]   # 求一个底的长
    l2 = p2[1]   # 求另一个底的长
    area = (l1 + l2)*height/2
    return area

def f1(x):
    return 2*x+3

x1 = float(input("请输入第一个点的横坐标值："))
x2 = float(input("请输入第二个点的横坐标值："))
y1 = f1(x1)
y2 = f1(x2)
area = reg_area((x1, y1), (x2, y2))
print("此梯形的面积为：", area)
```

​       结果：

<img src="https://tva1.sinaimg.cn/large/e6c9d24ely1h275npld9cj20k208imxh.jpg" style="zoom:50%;" />

### 近似求解不规则图形的面积

- 绘制一条曲线

```python
import numpy as np
import matplotlib.pyplot as plt
from IPython import display

def f(x):
    return x**2+4

def irr_area(x1, x2, intervals = 1000):
    if x1 <= x2:
        x_left = x1
        x_right = x2
    else:
        x_left = x2
        x_right = x1
    dx = (x_right-x_left)/intervals
    area = 0
    x_temp = x_left
    for i in range(intervals):
        area_temp = dx * (x_temp**2+4)
        area += area_temp
        x_temp += dx
    return area

x1 = float(input("请输入第一个点的横坐标值："))
x2 = float(input("请输入第二个点的横坐标值："))
y1 = f(x1)
y2 = f(x2)

x_temp = np.linspace(x1, x2, 1000)
y_temp = f(x_temp)
plt.plot(x_temp, y_temp)
plt.show()
%matplotlib inline
```

<img src="https://tva1.sinaimg.cn/large/e6c9d24ely1h275sgiqrhj20kg04kwej.jpg" style="zoom: 50%;" />

<img src="https://tva1.sinaimg.cn/large/e6c9d24ely1h275t1nbn2j20kg0b6t8x.jpg" style="zoom:50%;" />

- 近似求解，设定40次，越往后矩形分割的越小，值越精准

```py
for i in range(40):
    area = irr_area(-5, 6, 500*(i+1))
    print("此函数图像在这两点与横坐标轴之间围成的图形面积近似为：", area)
```

​       结果：

<img src="https://tva1.sinaimg.cn/large/e6c9d24ely1h275uuq0u1j20t00ak42j.jpg" style="zoom:50%;" />

## 定义

- 矩形块的面积与曲线围城的面积误差越来越小

<img src="https://tva1.sinaimg.cn/large/e6c9d24ely1h2764rnvk0j20pq08a74o.jpg" style="zoom: 33%;" />

- 黎曼积分：在闭区间[a,b]上若不同的取样方法获得的黎曼积分和<img src="https://tva1.sinaimg.cn/large/e6c9d24ely1h2769f6jfyj20800263yc.jpg" style="zoom:33%;" />最终都趋于同样的极限，则称该极限为黎曼积分<img src="https://tva1.sinaimg.cn/large/e6c9d24ely1h276af37o9j206e02ct8j.jpg" style="zoom:33%;" />

## 牛顿—莱布尼兹公式

### 定义

<img src="https://tva1.sinaimg.cn/large/e6c9d24ely1h276etowqij20j0042q2x.jpg" style="zoom: 50%;" />

- F(x)：f(x)的原函数
- C：常数
- a，b：积分区间

### 意义

- 提供了**求积分问题的有效方法**
  - 反向求出被积函数的原函数
  - 将复杂的积分运算转化为简单的加减运算
- 架起了**微分学和积分学之间的桥梁**
  - 历史上微分学和积分学起初是独立发展的
- 被称为“微积分基本定理”

Question：一个值恒为正的函数，考虑其几何意义，我们通过积分求出的值，是它和X轴围成面积的准确值，还是一个极度逼近的近似值?

Answer：**准确值**

# 泰勒展开

## 定义

<img src="https://tva1.sinaimg.cn/large/e6c9d24ely1h276t7m8trj212u04k3ys.jpg" style="zoom:33%;" />

​       最后一项称之为余项，分为拉格朗日余项和皮亚诺型余项

- **所有函数均可由多项式函数拟合**
  - 多项式函数：易于计算，可以快速获得结果
- 所有的复杂函数都是用泰勒展开转换成多项式函数计算的
- 泰勒展开是有适用范围的
- 当a=0时，泰勒公式被称之为麦克劳林公式，泰勒展开称之为麦克劳林展开

## 常用函数的泰勒展开式

<img src="https://tva1.sinaimg.cn/large/e6c9d24ely1h276xkpeyij20ig0j6aaw.jpg" style="zoom:50%;" />

## 如何理解

<img src="https://tva1.sinaimg.cn/large/e6c9d24ely1h276zbh0qfj20ky0jejsd.jpg" style="zoom: 33%;" />

​       **用多个函数拟合一个函数！～**
